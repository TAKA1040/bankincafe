import pandas as pd
import os
from datetime import datetime

def create_database_insert_sql():
    """å®Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ•å…¥ç”¨SQLã‚’ç”Ÿæˆ"""
    
    base_path = r"C:\Windsurf\bankincafe\è«‹æ±‚æ›¸ã‚·ã‚¹ãƒ†ãƒ ç”»åƒ\hondata"
    output_path = r"C:\Windsurf\bankincafe\supabase"
    
    try:
        # å„è¾æ›¸CSVã‚’èª­ã¿è¾¼ã¿
        targets_df = pd.read_csv(f"{base_path}\\targets_dictionary.csv", encoding='utf-8-sig')
        actions_df = pd.read_csv(f"{base_path}\\actions_dictionary.csv", encoding='utf-8-sig')
        positions_df = pd.read_csv(f"{base_path}\\positions_dictionary.csv", encoding='utf-8-sig')
        
        print(f"è¾æ›¸ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:")
        print(f"  - Targets: {len(targets_df)}ä»¶")
        print(f"  - Actions: {len(actions_df)}ä»¶") 
        print(f"  - Positions: {len(positions_df)}ä»¶")
        
        # SQLç”Ÿæˆé–‹å§‹
        sql_content = f"""-- å®Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸æŠ•å…¥SQL
-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

-- =====================================
-- 1. TARGETS (å¯¾è±¡ãƒã‚¹ã‚¿ãƒ¼) ã®æ›´æ–°
-- =====================================

"""
        
        # Targetsãƒ†ãƒ¼ãƒ–ãƒ«ç”¨SQLç”Ÿæˆ
        target_categories = targets_df['category'].unique()
        
        for category in target_categories:
            keywords = targets_df[targets_df['category'] == category]['keyword'].tolist()
            keywords_str = ', '.join([f"'{kw}'" for kw in keywords])
            
            sql_content += f"""-- {category}ã®æ›´æ–°/è¿½åŠ 
INSERT INTO targets (name, description, keywords, created_at, updated_at)
VALUES (
  '{category}',
  '{category}é–¢é€£ã®ä½œæ¥­å¯¾è±¡',
  ARRAY[{keywords_str}],
  NOW(),
  NOW()
)
ON CONFLICT (name) DO UPDATE SET
  keywords = EXCLUDED.keywords,
  updated_at = NOW();

"""
        
        # Actionsãƒ†ãƒ¼ãƒ–ãƒ«ç”¨SQLç”Ÿæˆ
        sql_content += """
-- =====================================
-- 2. ACTIONS (å‹•ä½œãƒã‚¹ã‚¿ãƒ¼) ã®æ›´æ–°
-- =====================================

"""
        
        action_categories = actions_df['category'].unique()
        
        for category in action_categories:
            keywords = actions_df[actions_df['category'] == category]['keyword'].tolist()
            keywords_str = ', '.join([f"'{kw}'" for kw in keywords])
            
            sql_content += f"""-- {category}ã®æ›´æ–°/è¿½åŠ 
INSERT INTO actions (name, description, keywords, created_at, updated_at)
VALUES (
  '{category}',
  '{category}é–¢é€£ã®ä½œæ¥­å‹•ä½œ',
  ARRAY[{keywords_str}],
  NOW(),
  NOW()
)
ON CONFLICT (name) DO UPDATE SET
  keywords = EXCLUDED.keywords,
  updated_at = NOW();

"""
        
        # Positionsãƒ†ãƒ¼ãƒ–ãƒ«ç”¨SQLç”Ÿæˆ
        sql_content += """
-- =====================================
-- 3. POSITIONS (ä½ç½®ãƒã‚¹ã‚¿ãƒ¼) ã®æ›´æ–°
-- =====================================

"""
        
        position_categories = positions_df['category'].unique()
        
        for category in position_categories:
            keywords = positions_df[positions_df['category'] == category]['keyword'].tolist()
            keywords_str = ', '.join([f"'{kw}'" for kw in keywords])
            
            sql_content += f"""-- {category}ã®æ›´æ–°/è¿½åŠ 
INSERT INTO positions (name, description, keywords, created_at, updated_at)
VALUES (
  '{category}',
  '{category}é–¢é€£ã®ä½ç½®æƒ…å ±',
  ARRAY[{keywords_str}],
  NOW(),
  NOW()
)
ON CONFLICT (name) DO UPDATE SET
  keywords = EXCLUDED.keywords,
  updated_at = NOW();

"""
        
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—SQL
        sql_content += f"""
-- =====================================
-- 4. å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
-- =====================================

-- ä»Šå›ã®æ›´æ–°ã§å«ã¾ã‚Œã¦ã„ãªã„å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
DELETE FROM targets WHERE updated_at < '{datetime.now().strftime('%Y-%m-%d')}' AND name NOT IN ({', '.join([f"'{cat}'" for cat in target_categories])});
DELETE FROM actions WHERE updated_at < '{datetime.now().strftime('%Y-%m-%d')}' AND name NOT IN ({', '.join([f"'{cat}'" for cat in action_categories])});
DELETE FROM positions WHERE updated_at < '{datetime.now().strftime('%Y-%m-%d')}' AND name NOT IN ({', '.join([f"'{cat}'" for cat in position_categories])});

-- =====================================
-- 5. æ›´æ–°çµæœç¢ºèª
-- =====================================

SELECT 'targets' as table_name, COUNT(*) as record_count FROM targets
UNION ALL
SELECT 'actions' as table_name, COUNT(*) as record_count FROM actions  
UNION ALL
SELECT 'positions' as table_name, COUNT(*) as record_count FROM positions;
"""
        
        # SQLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        sql_file_path = f"{output_path}\\update_real_dictionary.sql"
        with open(sql_file_path, 'w', encoding='utf-8') as f:
            f.write(sql_content)
        
        print(f"\nSQLæŠ•å…¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {sql_file_path}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ•å…¥ç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”Ÿæˆ
        create_csv_for_import(targets_df, actions_df, positions_df, base_path)
        
        return sql_file_path
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def create_csv_for_import(targets_df, actions_df, positions_df, base_path):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ•å…¥ç”¨ã®çµ±åˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    
    # Targetsãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
    targets_import = []
    for category in targets_df['category'].unique():
        keywords = targets_df[targets_df['category'] == category]['keyword'].tolist()
        targets_import.append({
            'table_type': 'targets',
            'name': category,
            'description': f'{category}é–¢é€£ã®ä½œæ¥­å¯¾è±¡',
            'keywords': '|'.join(keywords)
        })
    
    # Actionsãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
    actions_import = []
    for category in actions_df['category'].unique():
        keywords = actions_df[actions_df['category'] == category]['keyword'].tolist()
        actions_import.append({
            'table_type': 'actions',
            'name': category,
            'description': f'{category}é–¢é€£ã®ä½œæ¥­å‹•ä½œ',
            'keywords': '|'.join(keywords)
        })
    
    # Positionsãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
    positions_import = []
    for category in positions_df['category'].unique():
        keywords = positions_df[positions_df['category'] == category]['keyword'].tolist()
        positions_import.append({
            'table_type': 'positions',
            'name': category,
            'description': f'{category}é–¢é€£ã®ä½ç½®æƒ…å ±',
            'keywords': '|'.join(keywords)
        })
    
    # çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    all_import_data = targets_import + actions_import + positions_import
    import_df = pd.DataFrame(all_import_data)
    
    # CSVå‡ºåŠ›
    csv_file_path = f"{base_path}\\dictionary_import_unified.csv"
    import_df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')
    print(f"çµ±åˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {csv_file_path}")
    
    # å„ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ã®CSVã‚‚ç”Ÿæˆ
    targets_import_df = pd.DataFrame(targets_import)
    targets_import_df.to_csv(f"{base_path}\\targets_import.csv", index=False, encoding='utf-8-sig')
    
    actions_import_df = pd.DataFrame(actions_import)
    actions_import_df.to_csv(f"{base_path}\\actions_import.csv", index=False, encoding='utf-8-sig')
    
    positions_import_df = pd.DataFrame(positions_import)
    positions_import_df.to_csv(f"{base_path}\\positions_import.csv", index=False, encoding='utf-8-sig')
    
    print("å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨CSVã‚‚ç”Ÿæˆå®Œäº†")

def show_summary():
    """ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ¦‚è¦ã‚’è¡¨ç¤º"""
    
    base_path = r"C:\Windsurf\bankincafe\è«‹æ±‚æ›¸ã‚·ã‚¹ãƒ†ãƒ ç”»åƒ\hondata"
    
    print("\n" + "="*60)
    print("ğŸ“‹ å®Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ•å…¥æº–å‚™å®Œäº†")
    print("="*60)
    
    print("\nğŸ¯ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print("1. SQLæŠ•å…¥ãƒ•ã‚¡ã‚¤ãƒ«:")
    print("   - C:\\Windsurf\\bankincafe\\supabase\\update_real_dictionary.sql")
    
    print("\n2. CSVæŠ•å…¥ãƒ•ã‚¡ã‚¤ãƒ«:")
    print("   - dictionary_import_unified.csv (çµ±åˆç‰ˆ)")
    print("   - targets_import.csv (å¯¾è±¡ãƒã‚¹ã‚¿ãƒ¼)")
    print("   - actions_import.csv (å‹•ä½œãƒã‚¹ã‚¿ãƒ¼)")
    print("   - positions_import.csv (ä½ç½®ãƒã‚¹ã‚¿ãƒ¼)")
    
    print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabaseã§å®Ÿè¡Œ")
    print("2. ã¾ãŸã¯ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabaseã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    print("3. å‹•ä½œç¢ºèª")
    
    print("\nğŸ’¡ æŠ•å…¥å†…å®¹:")
    try:
        targets_df = pd.read_csv(f"{base_path}\\targets_dictionary.csv", encoding='utf-8-sig')
        actions_df = pd.read_csv(f"{base_path}\\actions_dictionary.csv", encoding='utf-8-sig')
        positions_df = pd.read_csv(f"{base_path}\\positions_dictionary.csv", encoding='utf-8-sig')
        
        print(f"   - Targets: {len(targets_df['category'].unique())}ã‚«ãƒ†ã‚´ãƒª, {len(targets_df)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        print(f"   - Actions: {len(actions_df['category'].unique())}ã‚«ãƒ†ã‚´ãƒª, {len(actions_df)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        print(f"   - Positions: {len(positions_df['category'].unique())}ã‚«ãƒ†ã‚´ãƒª, {len(positions_df)}ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
    except:
        print("   - çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—")

def main():
    print("å®Ÿãƒ‡ãƒ¼ã‚¿è¾æ›¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æŠ•å…¥æº–å‚™ã‚’é–‹å§‹...")
    
    sql_file_path = create_database_insert_sql()
    
    if sql_file_path:
        show_summary()
    else:
        print("å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()